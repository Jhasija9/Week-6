{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d4a32c5",
   "metadata": {},
   "source": [
    "Task: File Ingestion and Schema validation\n",
    "Take any csv/text file of 2+ GB of your choice. --- (You can do this assignment on Google colab)\n",
    "\n",
    "Read the file ( Present approach of reading the file )\n",
    "\n",
    "Try different methods of file reading eg: Dask, Modin, Ray, pandas and present your findings in term of computational efficiency\n",
    "\n",
    "Perform basic validation on data columns : eg: remove special character , white spaces from the col name\n",
    "\n",
    "As you already know the schema hence create a YAML file and write the column name in YAML file. --define separator of\n",
    "read and write file, column name in YAML\n",
    "\n",
    "Validate number of columns and column name of ingested file with YAML.\n",
    "\n",
    "Write the file in pipe separated text file (|) in gz format.\n",
    "\n",
    "Create a summary of the file:\n",
    "\n",
    "Total number of rows,\n",
    "\n",
    "total number of columns\n",
    "\n",
    "file size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4053e2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81b5ef94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read csv with dask:  0.0033309459686279297 sec\n"
     ]
    }
   ],
   "source": [
    "from dask import dataframe as dd\n",
    "start=time.time()\n",
    "dask_dd=dd.read_csv('data.csv')\n",
    "end=time.time()\n",
    "print(\"Read csv with dask: \",(end-start),\"sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bacf79c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read csv with pandas:  15.176892042160034 sec\n"
     ]
    }
   ],
   "source": [
    "start=time.time()\n",
    "pdd=pd.read_csv('data.csv')\n",
    "end=time.time()\n",
    "print(\"Read csv with pandas: \",(end-start),\"sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5ad3654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing utilityfile.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile utilityfile.py\n",
    "\n",
    "import logging\n",
    "import os\n",
    "import yaml\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import gc\n",
    "import re\n",
    "\n",
    "\n",
    "#reading the file\n",
    "\n",
    "def read_file(filepath):\n",
    "    with open(filepath,'r') as stream:\n",
    "        try:\n",
    "            return yaml.safe_load(stream)\n",
    "        except yaml.YAMLError as exc:\n",
    "            logging.error(exc)\n",
    "            \n",
    "# replacing the character\n",
    "\n",
    "def replace(string, char):\n",
    "    pattern=char + '{2,}'\n",
    "    string= re.sub(pattern,char,string)\n",
    "    return string\n",
    "\n",
    "\n",
    "# standardizes columns and validates dataframe YAML against validation YAML\n",
    "\n",
    "def col_header_valid(df, table_config):\n",
    "    df.columns=df.columns.str.lower()\n",
    "    df.columns = df.columns.str.replace('[^\\w]', '_', regex=True)\n",
    "    df.columns= list(map(lambda x: x.strip('_'), list(df.columns)))\n",
    "    df.columns= list(map(lambda x: replace(x, '_'), list(df.columns)))\n",
    "    expected_col= list(map(lambda x:x.lower(),table_config['columns']))\n",
    "    expected_col.sort()\n",
    "    df.columns = list(map(lambda x: x.lower(), list(df.columns)))\n",
    "    \n",
    "    if len(expected_col)==len(df.columns) and list(expected_col)==list(df.columns):\n",
    "        print(\"Column name and column length validation passed.\")\n",
    "        return 1\n",
    "    else:\n",
    "        print(\"Column name and column length validation failed.\")\n",
    "        mismatched_columns_file=list(set(df.columns).difference(expected_col))\n",
    "        print(\"Following file columns are not in the YAML file\",mismatched_columns_file)\n",
    "        missing_YAML_file = list(set(expected_col).difference(df.columns))\n",
    "        print(\"Following YAML columns are not in the file uploaded\",missing_YAML_file)\n",
    "        logging.info(f'df columns: {df.columns}')\n",
    "        logging.info(f'expected columns: {expected_col}')\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73d20d96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting validation_yaml.csv\n"
     ]
    }
   ],
   "source": [
    "%%writefile validation_yaml.csv\n",
    "\n",
    "file_type: csv\n",
    "dataset_name: validation\n",
    "file_name: validation_yaml\n",
    "table_name: example\n",
    "inbound_delimiter: \",\"\n",
    "outbound_delimiter: \"|\"\n",
    "skip_leading_rows: 1\n",
    "columns: \n",
    "    - date\n",
    "    - game_size\n",
    "    - match_id\n",
    "    - match_mode\n",
    "    - party_size\n",
    "    - player_assists\n",
    "    - player_dbno\n",
    "    - player_dist_ride\n",
    "    - player_dist_walk\n",
    "    - player_dmg\n",
    "    - player_kills\n",
    "    - player_name\n",
    "    - player_survive_time\n",
    "    - team_id\n",
    "    - team_placement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "321819a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting pubgdata.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile pubgdata.yaml\n",
    "\n",
    "file_type: yaml\n",
    "dataset_name: pubg_agg_match\n",
    "file_name: pubg_agg_match_stats_0\n",
    "table_name: ast\n",
    "inbound_delimiter: ','\n",
    "outbound_delimiter: '|'\n",
    "skip_leading_rows: 1\n",
    "columns: \n",
    "    - date\n",
    "    - game_size\n",
    "    - match_id\n",
    "    - match_mode\n",
    "    - party_size\n",
    "    - player_assists\n",
    "    - player_dbno\n",
    "    - player_dist_ride\n",
    "    - player_dist_walk\n",
    "    - player_dmg\n",
    "    - player_kills\n",
    "    - player_name\n",
    "    - player_survive_time\n",
    "    - team_id\n",
    "    - team_placement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c07bec54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utilityfile as util\n",
    "\n",
    "config_data=util.read_file(\"validation_yaml.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f001a18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'csv'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_data['file_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3c57cc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'file_type': 'csv',\n",
       " 'dataset_name': 'validation',\n",
       " 'file_name': 'validation_yaml',\n",
       " 'table_name': 'example',\n",
       " 'inbound_delimiter': ',',\n",
       " 'outbound_delimiter': '|',\n",
       " 'skip_leading_rows': 1,\n",
       " 'columns': ['date',\n",
       "  'game_size',\n",
       "  'match_id',\n",
       "  'match_mode',\n",
       "  'party_size',\n",
       "  'player_assists',\n",
       "  'player_dbno',\n",
       "  'player_dist_ride',\n",
       "  'player_dist_walk',\n",
       "  'player_dmg',\n",
       "  'player_kills',\n",
       "  'player_name',\n",
       "  'player_survive_time',\n",
       "  'team_id',\n",
       "  'team_placement']}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99f7ca02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column name and column length validation passed.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validate the header of the file\n",
    "\n",
    "util.col_header_valid(dask_dd,config_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d1744b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>age</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Delhi</td>\n",
       "      <td>34</td>\n",
       "      <td>India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lima</td>\n",
       "      <td>30</td>\n",
       "      <td>Peru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Istanbul</td>\n",
       "      <td>16</td>\n",
       "      <td>Turkey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Riyadh</td>\n",
       "      <td>33</td>\n",
       "      <td>Saudi Arabia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       city  age       Country\n",
       "0     Delhi   34         India\n",
       "1      Lima   30          Peru\n",
       "2  Istanbul   16        Turkey\n",
       "3    Riyadh   33  Saudi Arabia"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "invalid_data= pd.read_csv(\"test_data.csv\")\n",
    "invalid_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02f5eeb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column name and column length validation failed.\n",
      "Following file columns are not in the YAML file ['country', 'city', 'age']\n",
      "Following YAML columns are not in the file uploaded ['player_dbno', 'party_size', 'match_id', 'player_name', 'player_dist_walk', 'player_dmg', 'team_placement', 'team_id', 'game_size', 'date', 'player_survive_time', 'match_mode', 'player_dist_ride', 'player_assists', 'player_kills']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "util.col_header_valid(invalid_data,config_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "98456cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming dask_dd is your DataFrame\n",
    "columns_df = pd.DataFrame([dask_dd.columns])\n",
    "\n",
    "# Save the columns as a single-row CSV with pipe delimiter and optional compression\n",
    "columns_df.to_csv('output.txt', sep='|', index=False, header=False)\n",
    "\n",
    "# Optional: If you want to compress the file\n",
    "columns_df.to_csv('output.txt.gz', sep='|', index=False, header=False, compression='gzip')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "de51ddbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of rows: 13849287\n",
      "Total number of columns: 15\n",
      "File size: 140 bytes\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# get the file size\n",
    "file_size = os.path.getsize('output.txt.gz')\n",
    "\n",
    "# get the total number of rows and columns\n",
    "num_rows = len(dask_dd)\n",
    "num_cols = len(dask_dd.columns)\n",
    "\n",
    "# print the summary\n",
    "print(f\"Total number of rows: {num_rows}\")\n",
    "print(f\"Total number of columns: {num_cols}\")\n",
    "print(f\"File size: {file_size} bytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06bdc30b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
